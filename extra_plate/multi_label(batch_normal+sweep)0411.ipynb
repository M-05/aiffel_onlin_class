{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-bert\n",
    "!pip install keras-radam\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d35c78",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3675ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import 및 주요 라이브러리 버전 확인 \n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import uuid\n",
    "# uuid.uuid4() -> UUID('e4392169-4184-43ba-88c9-157d87472c82')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Dense, GlobalMaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import Input, Model\n",
    "from keras import optimizers\n",
    "\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "from keras_radam import RAdam\n",
    "from keras_radam.training import RAdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34bbe6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9167f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_df = pd.read_csv(\"DKTC_train.csv\", usecols=['class','conversation'])\n",
    "immora_df = pd.read_csv(\"immoral_extra(oov).csv\", usecols=['class','conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b71087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타 괴롭힘 대화      1094\n",
       "갈취 대화           981\n",
       "직장 내 괴롭힘 대화     979\n",
       "협박 대화           896\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d756ad4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "위협대화    118140\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immora_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868af53",
   "metadata": {},
   "source": [
    "### 섞고 정렬하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1af8a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    dktc_df = dktc_df.sample(frac=1).reset_index(drop=True) #많이 섞기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba46b0",
   "metadata": {},
   "source": [
    "### class's label 숫자로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b19afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>야 너 일을 왜 그렇게 하냐\\n어제 말씀해주신대로.\\n그래 내가 그렇게 시켰다는거야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>야 거기\\n저요?\\n거기 너 말고 누구 있냐?\\n왜 그러시죠?\\n너 돈좀 있냐?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>우리자식살려내 못살리면 다 죽여버릴거야\\n최선을 다 하겠습니다\\n하지만 지금 위급한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>너 니 자식 살리고 싶지. 그러면 빨리 널 나에게 보낸 인간 불어.\\n.말못해.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>아 찐따새끼 진짜 쟤 저렇게 맞고도 학교 잘 나온다\\n그러게 쟤도 참 징하다 나 같...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>진짜 개 웃기게 생겼네 \\n뭐어?\\n다운증후군?야 그거 걸린 애들은 왜 다 너같이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>수진 씨 이거 일처리를 왜 이렇게 해요?\\n 네? 혹시 무슨 부분 때문인지 말씀해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>내일까지 레벨 몇 만들어와\\n응? 나 낼 시험인데\\n해오라고\\n안돼.\\n또 맞고싶냐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>김사장 빌려간 돈 언제 줄거야?\\n약속날짜는 이번주 주말아닙니까\\n그렇긴한데 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어머 은지야 너 이 레포트 완전 잘썼다\\n고마워 며칠 밤을 꼬박 새웠는지 몰라.\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                       conversation\n",
       "0     직장 내 괴롭힘 대화  야 너 일을 왜 그렇게 하냐\\n어제 말씀해주신대로.\\n그래 내가 그렇게 시켰다는거야...\n",
       "1           갈취 대화  야 거기\\n저요?\\n거기 너 말고 누구 있냐?\\n왜 그러시죠?\\n너 돈좀 있냐?\\n...\n",
       "2           협박 대화  우리자식살려내 못살리면 다 죽여버릴거야\\n최선을 다 하겠습니다\\n하지만 지금 위급한...\n",
       "3           협박 대화  너 니 자식 살리고 싶지. 그러면 빨리 널 나에게 보낸 인간 불어.\\n.말못해.\\n...\n",
       "4       기타 괴롭힘 대화  아 찐따새끼 진짜 쟤 저렇게 맞고도 학교 잘 나온다\\n그러게 쟤도 참 징하다 나 같...\n",
       "...           ...                                                ...\n",
       "3945    기타 괴롭힘 대화  진짜 개 웃기게 생겼네 \\n뭐어?\\n다운증후군?야 그거 걸린 애들은 왜 다 너같이 ...\n",
       "3946  직장 내 괴롭힘 대화  수진 씨 이거 일처리를 왜 이렇게 해요?\\n 네? 혹시 무슨 부분 때문인지 말씀해 ...\n",
       "3947    기타 괴롭힘 대화  내일까지 레벨 몇 만들어와\\n응? 나 낼 시험인데\\n해오라고\\n안돼.\\n또 맞고싶냐...\n",
       "3948        협박 대화  김사장 빌려간 돈 언제 줄거야?\\n약속날짜는 이번주 주말아닙니까\\n그렇긴한데 내가 ...\n",
       "3949        갈취 대화  어머 은지야 너 이 레포트 완전 잘썼다\\n고마워 며칠 밤을 꼬박 새웠는지 몰라.\\n...\n",
       "\n",
       "[3950 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba1ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_df[\"class\"] = dktc_df[\"class\"].astype('category')\n",
    "dktc_df[\"class\"] = dktc_df[\"class\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e840f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>아가야\\n네?\\n니 손목에 팔찌 너무이쁘다\\n아빠가 사주신거에요\\n어머 그래?\\n네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>야 임자 나 배고프다.\\n나 오늘 돈 없어\\n그럼 너희 집으로 가자\\n왜?엄마계셔서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>현수야 내가 좀 급해서 그러는데 500만원만 주면 안돼?\\n그런 큰돈이 지금 어딨어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>오 너가 새로 입사한 애냐?\\n네 반갑습네다. 제가 이 회사에 새로 취직한 사람입니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>뒤로 횡령하신 전적이 있으시던데?\\n어디서 뭘 봤는지 모르겠지만 잘못 봤어.\\n동료...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>2</td>\n",
       "      <td>영주씨 낼 뭐해요?\\n내일은 푹쉬어야죠.\\n내일 나 좀 도와줘\\n제가 왜 도와줘야 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>1</td>\n",
       "      <td>네가 그럼 그렇지.하긴 뭘하냐 개뿔\\n나는 이렇게 될 줄 알았니\\n맨날 말만 번지르...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>0</td>\n",
       "      <td>야 이 볼펜 나 줘\\n싫은데?\\n걍 줘\\n내가 왜?\\n아 그냥 주라고\\n아 왜이래\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>1</td>\n",
       "      <td>이것도 못푸냐?\\n너무 어려운데\\n지능이 낮어서 그럼\\n말이 너무한거 아니냐?\\n솔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>2</td>\n",
       "      <td>영희 씨 남자친구랑 데이트 가나 봐 오늘 옷차림이 화려하네\\n네? 그런 거 아닙니다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                       conversation\n",
       "0         0  아가야\\n네?\\n니 손목에 팔찌 너무이쁘다\\n아빠가 사주신거에요\\n어머 그래?\\n네...\n",
       "1         0  야 임자 나 배고프다.\\n나 오늘 돈 없어\\n그럼 너희 집으로 가자\\n왜?엄마계셔서...\n",
       "2         0  현수야 내가 좀 급해서 그러는데 500만원만 주면 안돼?\\n그런 큰돈이 지금 어딨어...\n",
       "3         2  오 너가 새로 입사한 애냐?\\n네 반갑습네다. 제가 이 회사에 새로 취직한 사람입니...\n",
       "4         0  뒤로 횡령하신 전적이 있으시던데?\\n어디서 뭘 봤는지 모르겠지만 잘못 봤어.\\n동료...\n",
       "...     ...                                                ...\n",
       "3945      2  영주씨 낼 뭐해요?\\n내일은 푹쉬어야죠.\\n내일 나 좀 도와줘\\n제가 왜 도와줘야 ...\n",
       "3946      1  네가 그럼 그렇지.하긴 뭘하냐 개뿔\\n나는 이렇게 될 줄 알았니\\n맨날 말만 번지르...\n",
       "3947      0  야 이 볼펜 나 줘\\n싫은데?\\n걍 줘\\n내가 왜?\\n아 그냥 주라고\\n아 왜이래\\...\n",
       "3948      1  이것도 못푸냐?\\n너무 어려운데\\n지능이 낮어서 그럼\\n말이 너무한거 아니냐?\\n솔...\n",
       "3949      2  영희 씨 남자친구랑 데이트 가나 봐 오늘 옷차림이 화려하네\\n네? 그런 거 아닙니다...\n",
       "\n",
       "[3950 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_df\n",
    "# 0: 갈취 대화, 1: 기타 괴롭힘 대화 , 2: 직장 내 괴롭힘 대화, 3: 협박 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: 갈취 대화, 1: 기타 괴롭힘 대화 , 2: 직장 내 괴롭힘 대화, 3: 협박 대화\n",
    "CLASS_NAMES = [\"갈취 대화\", \"기타 괴롭힘 대화\", \"직장 내 괴롭힘 대화\", \"협박 대화\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ce9c8",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c0093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test = train_test_split(dktc_df, \n",
    "                                  test_size=0.1, \n",
    "                                  random_state=5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "695b4a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3555, 2), (395, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be241bb9",
   "metadata": {},
   "source": [
    "### train_validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e90b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val = train_test_split(x_train, \n",
    "                                  test_size=0.2, \n",
    "                                  random_state=5555)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfaf6f1",
   "metadata": {},
   "source": [
    "### index 순차적으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da804e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=\"index\", inplace=True)\n",
    "x_val.reset_index(drop=\"index\", inplace=True)\n",
    "x_test.reset_index(drop=\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46aca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    811\n",
       " 2    707\n",
       " 0    689\n",
       " 3    637\n",
       " Name: class, dtype: int64,\n",
       " 1    184\n",
       " 2    180\n",
       " 0    177\n",
       " 3    170\n",
       " Name: class, dtype: int64,\n",
       " 0    115\n",
       " 1     99\n",
       " 2     92\n",
       " 3     89\n",
       " Name: class, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['class'].value_counts(),\\\n",
    "x_val['class'].value_counts(),\\\n",
    "x_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59ca02",
   "metadata": {},
   "source": [
    "### korBERT 불러와서 model_extra 빌딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e255d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 최대 길이 -> 미만[초과] 0으로 채우기[자르기]\n",
    "SEQ_LEN = 256\n",
    "\n",
    "pretrained_path =\"bert\"\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "DATA_COLUMN = \"conversation\"\n",
    "LABEL_COLUMN = \"class\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ec0f1",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddca234",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        if \"_\" in token:\n",
    "            token = token.replace(\"_\",\"\")\n",
    "            token = \"##\" + token\n",
    "        token_dict[token] = len(token_dict)\n",
    "        #key(문자) = value(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30569ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inherit_Tokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        if not self._cased:\n",
    "            text = text\n",
    "            \n",
    "            text = text.lower()\n",
    "        spaced = ''\n",
    "        for ch in text:\n",
    "            if self._is_punctuation(ch) or self._is_cjk_character(ch):\n",
    "                spaced += ' ' + ch + ' '\n",
    "            elif self._is_space(ch):\n",
    "                spaced += ' '\n",
    "            elif ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\n",
    "                continue\n",
    "            else:\n",
    "                spaced += ch\n",
    "        tokens = []\n",
    "        for word in spaced.strip().split():\n",
    "            tokens += self._word_piece_tokenize(word)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2783ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = inherit_Tokenizer(token_dict)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af52c4",
   "metadata": {},
   "source": [
    "### Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f61b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "    indices, targets = [], []\n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN) # conversation\n",
    "        indices.append(ids)\n",
    "        targets.append(data_df[LABEL_COLUMN][i]) # class\n",
    "    items = list(zip(indices, targets))\n",
    "    \n",
    "    indices, targets = zip(*items)\n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)], np.array(targets)\n",
    "\n",
    "def load_data(pandas_dataframe):\n",
    "    data_df = pandas_dataframe\n",
    "    \n",
    "    \n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str) # conversation\n",
    "\n",
    "\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "539139b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2844/2844 [00:01<00:00, 2002.69it/s]\n",
      "100%|██████████| 711/711 [00:00<00:00, 1900.16it/s]\n",
      "100%|██████████| 395/395 [00:00<00:00, 1973.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(x_train)\n",
    "val_x, val_y = load_data(x_val)\n",
    "test_x, test_y = load_data(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390d28e",
   "metadata": {},
   "source": [
    "### 모델 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f2afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm05\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /aiffel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"fff4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3e2f4",
   "metadata": {},
   "source": [
    "### wandb.init 에 들어갈 parameter¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c2bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "#     \"n_channel_1\" : 32,\n",
    "#     \"n_channel_2\" : 64,\n",
    "    \"n_dense_1\" : 256,\n",
    "    \"n_dense_2\" : 768,\n",
    "    \"n_dense_3\" : 4,  \n",
    "    \"learning_rate\" : 5e-5,\n",
    "    \"epochs\" : 5,\n",
    "    \"batch_size\" : 8,\n",
    "    \"weight_decay\" : 0.025,\n",
    "#     \"optimizer\" : tf.keras.optimizers.Adam(learning_rate=1e-4, weight_decay=0.01),\n",
    "#     \"loss\" : \"categorical_crossentropy\",\n",
    "    \"loss\" : \"sparse_categorical_crossentropy\",\n",
    "    \"metrics\" : [\"accuracy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236f324",
   "metadata": {},
   "source": [
    "### wandb.sweep의 매개 변수¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c46d0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "#     \"name\": \"test_for_sweep123213\", # 변동 가능. 잘 모르겠다 . wandb 페이지에서 어디에 찍히는지...\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": {\n",
    "#         \"optimizer\" : {\n",
    "#             'value' : 'adam'\n",
    "#             },\n",
    "        \"batch_size\" : {\n",
    "            \"values\" : [8, 16, 32]\n",
    "            },\n",
    "        \"learning_rate\" : {\n",
    "            \"min\" : 1e-6,\n",
    "            \"max\" : 1e-4 # 0에 가까울 수록\n",
    "            },\n",
    "        \"epochs\" : {\n",
    "            \"distribution\" : \"int_uniform\",\n",
    "            \"min\" : 8,\n",
    "            \"max\" : 15\n",
    "            }\n",
    "                    \n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728c324",
   "metadata": {},
   "source": [
    "### model 불러오고 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8614f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_dense_1, n_dense_2, n_dense_3):\n",
    "    model = load_trained_model_from_checkpoint(config_path,\n",
    "                                                checkpoint_path,\n",
    "# 미리 학습된 모델을 사용하여 새 데이터에 대한 예측을 수행하려는 경우 \"training = False\n",
    "#                                                 training=True, # 새 데이터에서 모델을 계속 훈련 \n",
    "                                            #     trainable=True,\n",
    "                                                seq_len=SEQ_LEN)\n",
    "    # trainable 설정\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the target layer and all subsequent layers\n",
    "    for layer in model.layers[-1:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    inputs = model.inputs[:2]\n",
    "    dense = model.layers[-1].output\n",
    "\n",
    "\n",
    "    x = GlobalMaxPooling1D(name=\"GMP\")(dense)\n",
    "    \n",
    "    x= tf.keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(n_dense_1, activation='relu', name=\"1st_dense\")(x)\n",
    "    \n",
    "    x= tf.keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(n_dense_2, activation='relu', name=\"2st_dense\")(x)\n",
    "    \n",
    "    x= tf.keras.layers.BatchNormalization()(x)\n",
    "    outputs = keras.layers.Dense(n_dense_3, activation='softmax', \n",
    "                               kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                              name = 'real_output')(x) # \n",
    "\n",
    "\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Flatten()(x)\n",
    "# x = GlobalAveragePooling1D()(x)\n",
    "# x = GlobalMaxPooling1D(name=\"Golbal_Max_Pooling\")(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d6c11",
   "metadata": {},
   "source": [
    "### checkpoint & earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6c555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d74dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_callbacks():\n",
    "    CK = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path, \"test_sweep.{epoch:02d}-{val_loss:.2f}.h5\"),\n",
    "                                              monitor='val_loss',\n",
    "                                              save_best_only = True,\n",
    "                                              save_weights_only = True)\n",
    "\n",
    "    ES = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "    \n",
    "    return CK, ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c013f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "140d296a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_dense_1': 256,\n",
       " 'n_dense_2': 768,\n",
       " 'n_dense_3': 4,\n",
       " 'learning_rate': 5e-05,\n",
       " 'epochs': 5,\n",
       " 'batch_size': 8,\n",
       " 'weight_decay': 0.025,\n",
       " 'loss': 'sparse_categorical_crossentropy',\n",
       " 'metrics': ['accuracy']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c4408",
   "metadata": {},
   "source": [
    "### model.fit 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96538718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global default_config\n",
    "\n",
    "    # wandb.init & config\n",
    "    run = wandb.init(config = default_config, \n",
    "                     entity = \"m05\",\n",
    "                     project = \"TrainingFasle_sweep\") # 변동 가능\n",
    "    config = wandb.config\n",
    "\n",
    "    # Model -> config.n_channel_1\n",
    "    model = build_model(config.n_dense_1, config.n_dense_2, config.n_dense_3)    \n",
    "    \n",
    "    # model.compile\n",
    "    model.compile(\n",
    "                  optimizer = RAdamOptimizer(config.learning_rate, \n",
    "                                              config.weight_decay),\n",
    "                  loss = config.loss,\n",
    "                  metrics= config.metrics)\n",
    "    \n",
    "    #keras_callbacks\n",
    "    CK, ES = keras_callbacks()\n",
    "    \n",
    "    # model.fit\n",
    "    model.fit(train_x, train_y,\n",
    "              epochs = config.epochs,\n",
    "              batch_size = config.batch_size,\n",
    "              validation_data = (val_x, val_y),\n",
    "              callbacks = [CK, ES , \n",
    "                           WandbCallback(training_data = (test_x[:30], test_y[:30]),\n",
    "                                        labels = CLASS_NAMES)]) # sweep's table에 적용시킨 하이퍼파라미터 수치를 기입이 된다.\n",
    "                                        \n",
    "    # model.save ㅠㅠ 저장이 안되었어.........ㅠㅠㅠㅠㅠ\n",
    "#     wandb.save(os.path.join(path, \"wandb.{}.h5\".format(str(uuid.uuid4()))))\n",
    "    \n",
    "    # evaluate test\n",
    "    test_loss, test_accuracy = model.evaluate(test_x, test_y, verbose=2)\n",
    "    \n",
    "    # wandb's 테이블쪽 column 추가하기\n",
    "    wandb.log({\"Test Accuracy Rate: \" : round(test_accuracy * 100, 2),\n",
    "               \"Test Error Rate: \" : round((1 - test_accuracy) * 100, 2)})\n",
    "    \n",
    "    run.finish() # run 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c832b0",
   "metadata": {},
   "source": [
    "### model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67862b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: rt2ckhhm\n",
      "Sweep URL: https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mvsjgfls with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.478622318761144e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m05/3rd_sweep/runs/mvsjgfls' target=\"_blank\">wobbly-sweep-1</a></strong> to <a href='https://wandb.ai/m05/3rd_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m05/3rd_sweep' target=\"_blank\">https://wandb.ai/m05/3rd_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m05/3rd_sweep/runs/mvsjgfls' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/runs/mvsjgfls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "89/89 [==============================] - 89s 829ms/step - loss: 1.4167 - accuracy: 0.2940 - val_loss: 1.3856 - val_accuracy: 0.2293\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 1.3103 - accuracy: 0.3871 - val_loss: 1.3271 - val_accuracy: 0.3797\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 1.1968 - accuracy: 0.4884 - val_loss: 1.2057 - val_accuracy: 0.4937\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 1.0868 - accuracy: 0.5647 - val_loss: 1.0744 - val_accuracy: 0.5767\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/12\n",
      "89/89 [==============================] - 71s 794ms/step - loss: 1.0034 - accuracy: 0.6167 - val_loss: 0.9693 - val_accuracy: 0.6329\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 0.9480 - accuracy: 0.6252 - val_loss: 0.9003 - val_accuracy: 0.6554\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 7.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 0.9062 - accuracy: 0.6582 - val_loss: 0.8478 - val_accuracy: 0.6807\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/12\n",
      "89/89 [==============================] - 71s 794ms/step - loss: 0.8609 - accuracy: 0.6698 - val_loss: 0.8106 - val_accuracy: 0.6892\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 0.8256 - accuracy: 0.6744 - val_loss: 0.7908 - val_accuracy: 0.6962\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/12\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 0.8058 - accuracy: 0.6937 - val_loss: 0.7709 - val_accuracy: 0.7060\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 8.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/12\n",
      "89/89 [==============================] - 71s 797ms/step - loss: 0.7590 - accuracy: 0.7113 - val_loss: 0.7506 - val_accuracy: 0.7046\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/12\n",
      "89/89 [==============================] - 71s 795ms/step - loss: 0.7178 - accuracy: 0.7257 - val_loss: 0.7303 - val_accuracy: 0.7089\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_034758-mvsjgfls/files/model-best)... Done. 9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 7s - loss: 0.7223 - accuracy: 0.7165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy Rate: </td><td>▁</td></tr><tr><td>Test Error Rate: </td><td>▁</td></tr><tr><td>accuracy</td><td>▁▃▄▅▆▆▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▃▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇▇██████</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy Rate: </td><td>71.65</td></tr><tr><td>Test Error Rate: </td><td>28.35</td></tr><tr><td>accuracy</td><td>0.72574</td></tr><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.73033</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.71777</td></tr><tr><td>val_accuracy</td><td>0.70886</td></tr><tr><td>val_loss</td><td>0.73033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-sweep-1</strong> at: <a href='https://wandb.ai/m05/3rd_sweep/runs/mvsjgfls' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/runs/mvsjgfls</a><br/>Synced 5 W&B file(s), 1 media file(s), 48 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230411_034758-mvsjgfls/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8pjf6gor with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.5286714508777e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m05/3rd_sweep/runs/8pjf6gor' target=\"_blank\">ethereal-sweep-2</a></strong> to <a href='https://wandb.ai/m05/3rd_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m05/3rd_sweep' target=\"_blank\">https://wandb.ai/m05/3rd_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m05/3rd_sweep/runs/8pjf6gor' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/runs/8pjf6gor</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "89/89 [==============================] - 91s 835ms/step - loss: 1.4433 - accuracy: 0.2651 - val_loss: 1.3811 - val_accuracy: 0.2855\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/9\n",
      "89/89 [==============================] - 71s 797ms/step - loss: 1.3129 - accuracy: 0.3678 - val_loss: 1.3206 - val_accuracy: 0.3868\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/9\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 1.2012 - accuracy: 0.4891 - val_loss: 1.1971 - val_accuracy: 0.5162\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/9\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 1.1049 - accuracy: 0.5591 - val_loss: 1.0626 - val_accuracy: 0.5809\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/9\n",
      "89/89 [==============================] - 71s 795ms/step - loss: 1.0216 - accuracy: 0.5977 - val_loss: 0.9583 - val_accuracy: 0.6217\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 9.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/9\n",
      "89/89 [==============================] - 71s 795ms/step - loss: 0.9554 - accuracy: 0.6269 - val_loss: 0.8838 - val_accuracy: 0.6414\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/9\n",
      "89/89 [==============================] - 71s 795ms/step - loss: 0.8975 - accuracy: 0.6582 - val_loss: 0.8324 - val_accuracy: 0.6610\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 8.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/9\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 0.8535 - accuracy: 0.6772 - val_loss: 0.7962 - val_accuracy: 0.6807\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/9\n",
      "89/89 [==============================] - 71s 796ms/step - loss: 0.8301 - accuracy: 0.6835 - val_loss: 0.7734 - val_accuracy: 0.6948\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_041211-8pjf6gor/files/model-best)... Done. 8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 8s - loss: 0.7661 - accuracy: 0.7165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy Rate: </td><td>▁</td></tr><tr><td>Test Error Rate: </td><td>▁</td></tr><tr><td>accuracy</td><td>▁▃▅▆▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>loss</td><td>█▇▅▄▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▇▆▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy Rate: </td><td>71.65</td></tr><tr><td>Test Error Rate: </td><td>28.35</td></tr><tr><td>accuracy</td><td>0.68354</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.77344</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>loss</td><td>0.83009</td></tr><tr><td>val_accuracy</td><td>0.6948</td></tr><tr><td>val_loss</td><td>0.77344</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-2</strong> at: <a href='https://wandb.ai/m05/3rd_sweep/runs/8pjf6gor' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/runs/8pjf6gor</a><br/>Synced 5 W&B file(s), 1 media file(s), 36 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230411_041211-8pjf6gor/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ucbcqnal with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.6468364710372185e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m05/3rd_sweep/runs/ucbcqnal' target=\"_blank\">swept-sweep-3</a></strong> to <a href='https://wandb.ai/m05/3rd_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m05/3rd_sweep' target=\"_blank\">https://wandb.ai/m05/3rd_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/sweeps/rt2ckhhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m05/3rd_sweep/runs/ucbcqnal' target=\"_blank\">https://wandb.ai/m05/3rd_sweep/runs/ucbcqnal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "89/89 [==============================] - 89s 837ms/step - loss: 1.4458 - accuracy: 0.2623 - val_loss: 1.3948 - val_accuracy: 0.2841\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best)... Done. 8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/13\n",
      "89/89 [==============================] - 71s 797ms/step - loss: 1.3977 - accuracy: 0.3006 - val_loss: 1.3745 - val_accuracy: 0.2982\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best)... Done. 9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/13\n",
      "89/89 [==============================] - 71s 797ms/step - loss: 1.3752 - accuracy: 0.3386 - val_loss: 1.3434 - val_accuracy: 0.3390\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best)... Done. 9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/13\n",
      "89/89 [==============================] - 71s 797ms/step - loss: 1.3308 - accuracy: 0.3604 - val_loss: 1.3053 - val_accuracy: 0.3741\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best)... Done. 9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/13\n",
      "89/89 [==============================] - 71s 797ms/step - loss: 1.2992 - accuracy: 0.3987 - val_loss: 1.2678 - val_accuracy: 0.4008\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best)... Done. 9.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/13\n",
      "89/89 [==============================] - 71s 795ms/step - loss: 1.2607 - accuracy: 0.4335 - val_loss: 1.2303 - val_accuracy: 0.4599\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best)... Done. 7.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/13\n",
      "89/89 [==============================] - 71s 795ms/step - loss: 1.2297 - accuracy: 0.4560 - val_loss: 1.1963 - val_accuracy: 0.4895\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1898, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2126, in _atexit_cleanup\n",
      "    logger.info(f\"got exitcode: {exit_code}\")\n",
      "Message: 'got exitcode: 1'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1898, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2135, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2362, in _on_finish\n",
      "    self._console_stop()  # TODO: there's a race here with jupyter console logging\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2169, in _console_stop\n",
      "    self._restore()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2109, in _restore\n",
      "    logger.info(\"restore\")\n",
      "Message: 'restore'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1898, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2135, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2362, in _on_finish\n",
      "    self._console_stop()  # TODO: there's a race here with jupyter console logging\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2169, in _console_stop\n",
      "    self._restore()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2115, in _restore\n",
      "    logger.info(\"restore done\")\n",
      "Message: 'restore done'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 1555, in finish\n",
      "    self._dir_watcher.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py\", line 409, in finish\n",
      "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
      "Message: 'scan save: %s %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/wandb-summary.json', 'wandb-summary.json')\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 1555, in finish\n",
      "    self._dir_watcher.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py\", line 409, in finish\n",
      "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
      "Message: 'scan save: %s %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/wandb-metadata.json', 'wandb-metadata.json')\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 1555, in finish\n",
      "    self._dir_watcher.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py\", line 409, in finish\n",
      "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
      "Message: 'scan save: %s %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176', 'model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176')\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 1555, in finish\n",
      "    self._dir_watcher.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py\", line 409, in finish\n",
      "    logger.info(\"scan save: %s %s\", file_path, save_name)\n",
      "Message: 'scan save: %s %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/media/graph/graph_summary_670ad3cea267498040f6.graph.json', 'media/graph/graph_summary_670ad3cea267498040f6.graph.json')\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 1558, in finish\n",
      "    self._pusher.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/file_pusher.py\", line 168, in finish\n",
      "    logger.info(\"shutting down file pusher\")\n",
      "Message: 'shutting down file pusher'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 1559, in finish\n",
      "    self._pusher.join()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/file_pusher.py\", line 173, in join\n",
      "    logger.info(\"waiting for file pusher\")\n",
      "Message: 'waiting for file pusher'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 77, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 284, in run_and_notify\n",
      "    self._do_upload_sync(event)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
      "    job.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 61, in run\n",
      "    self.push()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 137, in push\n",
      "    logger.info(\"Uploaded file %s\", self.save_path)\n",
      "Message: 'Uploaded file %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/requirements.txt',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 77, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 284, in run_and_notify\n",
      "    self._do_upload_sync(event)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
      "    job.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 61, in run\n",
      "    self.push()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 137, in push\n",
      "    logger.info(\"Uploaded file %s\", self.save_path)\n",
      "Message: 'Uploaded file %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/config.yaml',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 77, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 284, in run_and_notify\n",
      "    self._do_upload_sync(event)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
      "    job.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 61, in run\n",
      "    self.push()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 137, in push\n",
      "    logger.info(\"Uploaded file %s\", self.save_path)\n",
      "Message: 'Uploaded file %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/output.log',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 77, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 284, in run_and_notify\n",
      "    self._do_upload_sync(event)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
      "    job.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 61, in run\n",
      "    self.push()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 137, in push\n",
      "    logger.info(\"Uploaded file %s\", self.save_path)\n",
      "Message: 'Uploaded file %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/wandb-summary.json',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 77, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 284, in run_and_notify\n",
      "    self._do_upload_sync(event)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
      "    job.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 61, in run\n",
      "    self.push()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 137, in push\n",
      "    logger.info(\"Uploaded file %s\", self.save_path)\n",
      "Message: 'Uploaded file %s'\n",
      "Arguments: ('/aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 77, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.9/concurrent/futures/thread.py\", line 52, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 284, in run_and_notify\n",
      "    self._do_upload_sync(event)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/step_upload.py\", line 330, in _do_upload_sync\n",
      "    job.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 61, in run\n",
      "    self.push()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 137, in push\n",
      "    logger.info(\"Uploaded file %s\", self.save_path)\n",
      "Message: 'Uploaded file %s'\n",
      "Arguments: ('/tmp/tmpq3cz32rdwandb/7cqefx4o-model-best.h5',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/service/streams.py\", line 49, in run\n",
      "    self._target(**self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 174, in wandb_internal\n",
      "    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\n",
      "Message: 'Thread WriterThread:'\n",
      "Arguments: ()\n",
      "Thread WriterThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._process(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 380, in _process\n",
      "    self._wm.write(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/writer.py\", line 154, in write\n",
      "    write_handler(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/writer.py\", line 135, in _write\n",
      "    self._write_record(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/writer.py\", line 109, in _write_record\n",
      "    ret = self._ds.write(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/datastore.py\", line 293, in write\n",
      "    ret = self._write_data(s)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/datastore.py\", line 249, in _write_data\n",
      "    self._write_record(s)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/internal/datastore.py\", line 228, in _write_record\n",
      "    self._fp.write(s)\n",
      "OSError: [Errno 28] No space left on device\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
      "    resp = self._sock_client.read_server_response(timeout=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 285, in read_server_response\n",
      "    data = self._read_packet_bytes(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 269, in _read_packet_bytes\n",
      "    raise SockClientClosedError\n",
      "wandb.sdk.lib.sock_client.SockClientClosedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "    msg = self._read_message()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
      "    raise MessageRouterClosedError\n",
      "wandb.sdk.interface.router.MessageRouterClosedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 77, in message_loop\n",
      "    logger.warning(\"message_loop has been closed\")\n",
      "Message: 'message_loop has been closed'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2135, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2372, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 298, in wait\n",
      "    on_probe(probe_handle)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2337, in _on_probe_exit\n",
      "    result = handle.wait(timeout=0)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 281, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.sdk.lib.mailbox.MailboxError: transport failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1898, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2145, in _atexit_cleanup\n",
      "    self._console_stop()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2169, in _console_stop\n",
      "    self._restore()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2109, in _restore\n",
      "    logger.info(\"restore\")\n",
      "Message: 'restore'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "    model.fit(train_x, train_y,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2135, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2372, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 298, in wait\n",
      "    on_probe(probe_handle)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2337, in _on_probe_exit\n",
      "    result = handle.wait(timeout=0)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 281, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.sdk.lib.mailbox.MailboxError: transport failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1898, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2145, in _atexit_cleanup\n",
      "    self._console_stop()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2169, in _console_stop\n",
      "    self._restore()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2115, in _restore\n",
      "    logger.info(\"restore done\")\n",
      "Message: 'restore done'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-250:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 298, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_869/1500841380.py\", line 24, in train\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1230, in fit\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\", line 413, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 630, in on_epoch_end\n",
      "    self._save_model_as_artifact(epoch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1032, in _save_model_as_artifact\n",
      "    self.model.save(self.filepath[:-3], overwrite=True, save_format=\"tf\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 2145, in save\n",
      "    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/save.py\", line 149, in save_model\n",
      "    saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/keras/saving/saved_model/save.py\", line 90, in save\n",
      "    saved_nodes, node_paths = save_lib.save_and_return_nodes(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\", line 1238, in save_and_return_nodes\n",
      "    object_saver.save(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1262, in save\n",
      "    save_path, new_feed_additions = self._save_cached_when_graph_building(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\", line 1208, in _save_cached_when_graph_building\n",
      "    save_op = saver.save(file_prefix, options=options)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 300, in save\n",
      "    return save_fn()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 274, in save_fn\n",
      "    sharded_saves.append(saver.save(shard_prefix, options))\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\", line 83, in save\n",
      "    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in save_v2\n",
      "    return save_v2_eager_fallback(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1717, in save_v2_eager_fallback\n",
      "    _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: /aiffel/aiffel/DDD/wandb/run-20230411_043047-ucbcqnal/files/model-best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate4790094430563569176; No space left on device [Op:SaveV2]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2135, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2372, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 298, in wait\n",
      "    on_probe(probe_handle)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2337, in _on_probe_exit\n",
      "    result = handle.wait(timeout=0)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py\", line 281, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.sdk.lib.mailbox.MailboxError: transport failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1898, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2146, in _atexit_cleanup\n",
      "    self._backend.cleanup()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/backend/backend.py\", line 255, in cleanup\n",
      "    self.interface.join()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 638, in join\n",
      "    super().join()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 741, in join\n",
      "    _ = self._communicate_shutdown()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 551, in _communicate_shutdown\n",
      "    _ = self._communicate(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 285, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 60, in _communicate_async\n",
      "    future = self._router.send_and_receive(rec, local=local)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 94, in send_and_receive\n",
      "    self._send_message(rec)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 36, in _send_message\n",
      "    self._sock_client.send_record_communicate(record)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 216, in send_record_communicate\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-319:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-320:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-321:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-322:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-323:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-324:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    logger.info(f\"finishing run {self._get_path()}\")\n",
      "Message: 'finishing run m05/3rd_sweep/ucbcqnal'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 430, in _jupyter_teardown\n",
      "    self.notebook.save_history()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 445, in save_history\n",
      "    logger.info(\"not saving jupyter history\")\n",
      "Message: 'not saving jupyter history'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 431, in _jupyter_teardown\n",
      "    if self.notebook.save_ipynb():\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/jupyter.py\", line 373, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 930, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 435, in _jupyter_teardown\n",
      "    logger.info(\"cleaning up jupyter logic\")  # type: ignore\n",
      "Message: 'cleaning up jupyter logic'\n",
      "Arguments: ()\n",
      "Exception in thread Thread-325:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 288, in _run_job\n",
      "    wandb.wandb_lib.config_util.save_config_file_from_dict(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 95, in save_config_file_from_dict\n",
      "    conf_file.write(data)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 303, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3716, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 334, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1883, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1896, in _finish\n",
      "    hook.call()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 443, in _jupyter_teardown\n",
      "    ipython.display_pub.publish = ipython.display_pub._orig_publish\n",
      "AttributeError: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config,\n",
    "                       entity = 'm05', # 고유명사\n",
    "                       project = '3rd_sweep') # 변동가능\n",
    "\n",
    "# run the sweep\n",
    "wandb.agent(sweep_id,\n",
    "            count=10, # 10회만 돌린다.\n",
    "            function=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d51f91",
   "metadata": {},
   "source": [
    "OSError: [Errno 28] No space left on device  \n",
    "ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76147a32",
   "metadata": {},
   "source": [
    "### model's layer가 trainable인지 아닌지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3adaa9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-Token False\n",
      "Input-Segment False\n",
      "Embedding-Token False\n",
      "Embedding-Segment False\n",
      "Embedding-Token-Segment False\n",
      "Embedding-Position False\n",
      "Embedding-Dropout False\n",
      "Embedding-Norm False\n",
      "Encoder-1-MultiHeadSelfAttention False\n",
      "Encoder-1-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-1-MultiHeadSelfAttention-Add False\n",
      "Encoder-1-MultiHeadSelfAttention-Norm False\n",
      "Encoder-1-FeedForward False\n",
      "Encoder-1-FeedForward-Dropout False\n",
      "Encoder-1-FeedForward-Add False\n",
      "Encoder-1-FeedForward-Norm False\n",
      "Encoder-2-MultiHeadSelfAttention False\n",
      "Encoder-2-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-2-MultiHeadSelfAttention-Add False\n",
      "Encoder-2-MultiHeadSelfAttention-Norm False\n",
      "Encoder-2-FeedForward False\n",
      "Encoder-2-FeedForward-Dropout False\n",
      "Encoder-2-FeedForward-Add False\n",
      "Encoder-2-FeedForward-Norm False\n",
      "Encoder-3-MultiHeadSelfAttention False\n",
      "Encoder-3-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-3-MultiHeadSelfAttention-Add False\n",
      "Encoder-3-MultiHeadSelfAttention-Norm False\n",
      "Encoder-3-FeedForward False\n",
      "Encoder-3-FeedForward-Dropout False\n",
      "Encoder-3-FeedForward-Add False\n",
      "Encoder-3-FeedForward-Norm False\n",
      "Encoder-4-MultiHeadSelfAttention False\n",
      "Encoder-4-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-4-MultiHeadSelfAttention-Add False\n",
      "Encoder-4-MultiHeadSelfAttention-Norm False\n",
      "Encoder-4-FeedForward False\n",
      "Encoder-4-FeedForward-Dropout False\n",
      "Encoder-4-FeedForward-Add False\n",
      "Encoder-4-FeedForward-Norm False\n",
      "Encoder-5-MultiHeadSelfAttention False\n",
      "Encoder-5-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-5-MultiHeadSelfAttention-Add False\n",
      "Encoder-5-MultiHeadSelfAttention-Norm False\n",
      "Encoder-5-FeedForward False\n",
      "Encoder-5-FeedForward-Dropout False\n",
      "Encoder-5-FeedForward-Add False\n",
      "Encoder-5-FeedForward-Norm False\n",
      "Encoder-6-MultiHeadSelfAttention False\n",
      "Encoder-6-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-6-MultiHeadSelfAttention-Add False\n",
      "Encoder-6-MultiHeadSelfAttention-Norm False\n",
      "Encoder-6-FeedForward False\n",
      "Encoder-6-FeedForward-Dropout False\n",
      "Encoder-6-FeedForward-Add False\n",
      "Encoder-6-FeedForward-Norm False\n",
      "Encoder-7-MultiHeadSelfAttention False\n",
      "Encoder-7-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-7-MultiHeadSelfAttention-Add False\n",
      "Encoder-7-MultiHeadSelfAttention-Norm False\n",
      "Encoder-7-FeedForward False\n",
      "Encoder-7-FeedForward-Dropout False\n",
      "Encoder-7-FeedForward-Add False\n",
      "Encoder-7-FeedForward-Norm False\n",
      "Encoder-8-MultiHeadSelfAttention False\n",
      "Encoder-8-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-8-MultiHeadSelfAttention-Add False\n",
      "Encoder-8-MultiHeadSelfAttention-Norm False\n",
      "Encoder-8-FeedForward False\n",
      "Encoder-8-FeedForward-Dropout False\n",
      "Encoder-8-FeedForward-Add False\n",
      "Encoder-8-FeedForward-Norm False\n",
      "Encoder-9-MultiHeadSelfAttention False\n",
      "Encoder-9-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-9-MultiHeadSelfAttention-Add False\n",
      "Encoder-9-MultiHeadSelfAttention-Norm False\n",
      "Encoder-9-FeedForward False\n",
      "Encoder-9-FeedForward-Dropout False\n",
      "Encoder-9-FeedForward-Add False\n",
      "Encoder-9-FeedForward-Norm False\n",
      "Encoder-10-MultiHeadSelfAttention False\n",
      "Encoder-10-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-10-MultiHeadSelfAttention-Add False\n",
      "Encoder-10-MultiHeadSelfAttention-Norm False\n",
      "Encoder-10-FeedForward False\n",
      "Encoder-10-FeedForward-Dropout False\n",
      "Encoder-10-FeedForward-Add False\n",
      "Encoder-10-FeedForward-Norm False\n",
      "Encoder-11-MultiHeadSelfAttention False\n",
      "Encoder-11-MultiHeadSelfAttention-Dropout False\n",
      "Encoder-11-MultiHeadSelfAttention-Add False\n",
      "Encoder-11-MultiHeadSelfAttention-Norm False\n",
      "Encoder-11-FeedForward True\n",
      "Encoder-11-FeedForward-Dropout True\n",
      "Encoder-11-FeedForward-Add True\n",
      "Encoder-11-FeedForward-Norm True\n",
      "Encoder-12-MultiHeadSelfAttention True\n",
      "Encoder-12-MultiHeadSelfAttention-Dropout True\n",
      "Encoder-12-MultiHeadSelfAttention-Add True\n",
      "Encoder-12-MultiHeadSelfAttention-Norm True\n",
      "Encoder-12-FeedForward True\n",
      "Encoder-12-FeedForward-Dropout True\n",
      "Encoder-12-FeedForward-Add True\n",
      "Encoder-12-FeedForward-Norm True\n"
     ]
    }
   ],
   "source": [
    "# for layer in model.layers:\n",
    "#     print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565488e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85baad64",
   "metadata": {},
   "source": [
    "### Load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "283b5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model_from_checkpoint(\n",
    "                                            config_path,\n",
    "                                            checkpoint_path,\n",
    "    \n",
    "# 미리 학습된 모델을 사용하여 새 데이터에 대한 예측을 수행하려는 경우 \"training = False\n",
    "#     training=True, # 새 데이터에서 모델을 계속 훈련 \n",
    "#     trainable=True,\n",
    "    \n",
    "    seq_len=SEQ_LEN) # 최대 문장의 길이 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd0968bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "     # trainable 설정\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the target layer and all subsequent layers\n",
    "    for layer in model.layers[-1:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    inputs = model.inputs[:3]\n",
    "    dense = model.layers[-1].output\n",
    "    \n",
    "    x = GlobalMaxPooling1D(name=\"GMP\")(dense)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu', name=\"1st_dense\")(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(768, activation='relu', name=\"2st_dense\")(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    outputs = keras.layers.Dense(4, activation='softmax', \n",
    "                               kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                              name = 'real_output')(x) # \n",
    "\n",
    "\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "                optimizer = RAdamOptimizer(learning_rate=5e-4, \n",
    "                                              weight_decay=0.025),\n",
    "                loss = \"sparse_categorical_crossentropy\", \n",
    "#                 loss =tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics= [\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79a0adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = load_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2384eece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_model.load_weights(os.path.join(path,\"test_sweep.12-0.73.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011654c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a95a49",
   "metadata": {},
   "source": [
    "### Load dktc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "179d5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_test = pd.read_csv(\"DKTC_test.csv\", usecols=['class','conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c7fe22d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                       conversation\n",
       "0      NaN  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
       "1      NaN  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
       "2      NaN  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
       "3      NaN  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
       "4      NaN  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...\n",
       "..     ...                                                ...\n",
       "495    NaN  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...\n",
       "496    NaN  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...\n",
       "497    NaN  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...\n",
       "498    NaN  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...\n",
       "499    NaN  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f2281e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_convert_data(data_df):\n",
    "    global tokenizer\n",
    "    indices= []\n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN) # conversation\n",
    "        indices.append(ids)\n",
    "        \n",
    "    items = indices\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)]\n",
    "\n",
    "def predict_load_data(pd_dataframe):\n",
    "    data_df = pd_dataframe    \n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str) # conversation\n",
    "\n",
    "    data_x= predict_convert_data(data_df)\n",
    "\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdb105b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2142.81it/s]\n"
     ]
    }
   ],
   "source": [
    "test_set = predict_load_data(dktc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eefd419e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 13s 594ms/step\n"
     ]
    }
   ],
   "source": [
    "softmax_predict = multi_model.predict(test_set, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83dd5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53815144, 0.18725769, 0.1406211 , 0.13396977],\n",
       "       [0.04876035, 0.10863576, 0.7442904 , 0.09831352],\n",
       "       [0.06861415, 0.08023471, 0.56208897, 0.28906223],\n",
       "       ...,\n",
       "       [0.9460808 , 0.03791264, 0.00373516, 0.01227141],\n",
       "       [0.08469672, 0.04582196, 0.12751555, 0.7419658 ],\n",
       "       [0.06881882, 0.004638  , 0.01146716, 0.915076  ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5000229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaf12efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53815144, 0.18725769, 0.1406211 , 0.13396977], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b094c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.999323, 4.089197e-05)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_predict.max(), softmax_predict.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc208bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314118e8",
   "metadata": {},
   "source": [
    "### Softmax 값을 int 형태로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11dbfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_answer_label(*preds): # * 없으면 array([1, 1, 1, 1]) 이렇게 나오넹\n",
    "  preds_sum = np.zeros(preds[0].shape[0])\n",
    "  \n",
    "  for pred in preds:\n",
    "    preds_sum += np.argmax(pred, axis=-1)\n",
    "  \n",
    "  return np.round(preds_sum / len(preds), 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31a9364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds= mean_answer_label(softmax_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91bf7967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 2, 3, 3, 0, 1, 0, 3, 1, 2, 2, 1, 3, 1, 1, 3, 1, 3, 1,\n",
       "       1, 0, 0, 2, 1, 1, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 2, 0,\n",
       "       1, 2, 3, 1, 1, 3, 0, 1, 0, 2, 2, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 0,\n",
       "       0, 1, 0, 3, 1, 2, 1, 2, 3, 2, 2, 0, 0, 2, 2, 3, 2, 2, 1, 3, 3, 1,\n",
       "       0, 2, 2, 2, 3, 1, 0, 2, 2, 2, 3, 1, 0, 0, 1, 3, 2, 2, 2, 1, 2, 3,\n",
       "       3, 3, 3, 2, 0, 0, 0, 2, 0, 0, 2, 0, 3, 0, 0, 0, 2, 0, 0, 2, 1, 1,\n",
       "       1, 1, 0, 3, 3, 3, 1, 1, 3, 1, 0, 0, 2, 3, 3, 3, 3, 0, 3, 1, 3, 2,\n",
       "       0, 3, 3, 2, 1, 1, 3, 1, 2, 3, 2, 1, 2, 1, 1, 0, 1, 2, 2, 0, 3, 1,\n",
       "       2, 2, 1, 1, 3, 1, 2, 2, 3, 1, 1, 3, 0, 3, 3, 1, 0, 1, 0, 0, 3, 1,\n",
       "       3, 3, 2, 0, 3, 2, 3, 1, 2, 2, 2, 2, 3, 0, 3, 2, 0, 1, 1, 3, 3, 3,\n",
       "       0, 2, 3, 3, 0, 1, 0, 3, 0, 3, 2, 3, 3, 1, 0, 0, 3, 3, 3, 1, 1, 0,\n",
       "       1, 3, 2, 0, 2, 0, 2, 0, 0, 2, 3, 2, 2, 0, 0, 2, 0, 2, 1, 3, 2, 1,\n",
       "       3, 1, 1, 3, 2, 0, 3, 2, 3, 2, 0, 0, 2, 1, 2, 2, 0, 3, 1, 2, 2, 2,\n",
       "       0, 2, 3, 1, 0, 0, 1, 1, 2, 0, 3, 1, 0, 1, 2, 3, 3, 2, 0, 0, 1, 3,\n",
       "       0, 2, 2, 0, 1, 3, 2, 2, 0, 1, 1, 3, 2, 3, 3, 0, 0, 0, 0, 1, 2, 2,\n",
       "       3, 3, 3, 0, 0, 1, 0, 0, 1, 1, 3, 2, 3, 3, 2, 2, 0, 0, 3, 3, 3, 2,\n",
       "       0, 0, 0, 2, 1, 1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 2, 3, 1, 0, 1, 3, 0,\n",
       "       2, 0, 0, 1, 0, 0, 2, 3, 2, 2, 1, 3, 2, 3, 2, 3, 0, 3, 0, 2, 0, 1,\n",
       "       3, 2, 0, 3, 1, 3, 2, 2, 1, 0, 2, 0, 2, 1, 0, 3, 3, 2, 1, 3, 3, 0,\n",
       "       0, 1, 0, 3, 0, 1, 1, 0, 0, 2, 2, 3, 1, 3, 0, 3, 1, 1, 0, 2, 2, 2,\n",
       "       1, 3, 2, 0, 0, 3, 3, 2, 2, 1, 3, 0, 2, 1, 2, 0, 2, 3, 0, 2, 3, 0,\n",
       "       2, 2, 3, 1, 3, 1, 1, 3, 2, 0, 3, 2, 3, 2, 0, 1, 0, 2, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 3, 0, 1, 2, 0, 0, 0, 2, 0, 0, 3, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e44c85",
   "metadata": {},
   "source": [
    "---\n",
    "저스트 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1276ca7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.max(), preds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "49943a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy에서 특정 숫자 counting하는 법\n",
    "np.count_nonzero(preds == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e309a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {0:\"기타 괴롭힘 대화\", 1:\"갈취 대화\", 2:'직장 내 괴롭힘 대화', 3:'협박 대화'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "acdb494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "29b364e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "갈취 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "직장 내 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "기타 괴롭힘 대화 입니다.\n",
      "협박 대화 입니다.\n",
      "협박 대화 입니다.\n"
     ]
    }
   ],
   "source": [
    "num_0 = []\n",
    "num_1 = []\n",
    "num_2 = []\n",
    "num_3 = []\n",
    "etc = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == 0:\n",
    "        print(category_dict[preds[i]],\"입니다.\")\n",
    "        num_0.append(i)\n",
    "    elif preds[i] == 1:\n",
    "        print(category_dict[preds[i]],\"입니다.\")\n",
    "        num_1.append(i)\n",
    "    elif preds[i] == 2:\n",
    "        print(category_dict[preds[i]],\"입니다.\")\n",
    "        num_2.append(i)\n",
    "    elif preds[i] == 3:\n",
    "        print(category_dict[preds[i]],\"입니다.\")\n",
    "        num_3.append(i)\n",
    "    else:\n",
    "        print(\"기타 입니다.\")\n",
    "        etc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e4b1786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff018c5a",
   "metadata": {},
   "source": [
    "저스트 테스트\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817ad83",
   "metadata": {},
   "source": [
    "### label 달아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e23d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_test['class'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f24b8b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3</td>\n",
       "      <td>야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>3</td>\n",
       "      <td>엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                       conversation\n",
       "0        0  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
       "1        2  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
       "2        2  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
       "3        1  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
       "4        2  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...\n",
       "..     ...                                                ...\n",
       "495      2  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...\n",
       "496      0  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...\n",
       "497      0  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...\n",
       "498      3  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...\n",
       "499      3  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5b0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_test.to_csv(\"dktc_test(sparse).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f7b59",
   "metadata": {},
   "source": [
    "### Sentence로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ec5dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_convert_data(data):\n",
    "    global tokenizer\n",
    "    indices= []\n",
    "    ids, segments = tokenizer.encode(data, max_len=SEQ_LEN) # conversation\n",
    "    indices.append(ids)\n",
    "        \n",
    "    items = indices\n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)]\n",
    "\n",
    "def category_predict(sentence):\n",
    "    category_dict = {0:\"기타 괴롭힘 대화\", 1:\"갈취 대화\", 2:'직장 내 괴롭힘 대화', 3:'협박 대화'}\n",
    "    global mod\n",
    "    \n",
    "    sentence = re.sub(\"[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\‘|\\<\\>`\\'…]+\", \"\", sentence)\n",
    "    sentence = re.sub(\"\\n+\", \" \", sentence)\n",
    "    sentence = re.sub(\"\\t+\", \" \", sentence)\n",
    "\n",
    "    data_x = sentence_convert_data(sentence)\n",
    "    predict = multi_model.predict(data_x)\n",
    "    preds= mean_answer_label(predict)\n",
    "\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == 0:\n",
    "            print(category_dict[preds[i]],\"입니다.\")\n",
    "        elif preds[i] == 1:\n",
    "            print(category_dict[preds[i]],\"입니다.\")\n",
    "        elif preds[i] == 2:\n",
    "            print(category_dict[preds[i]],\"입니다.\")\n",
    "        elif preds[i] == 3:\n",
    "            print(category_dict[preds[i]],\"입니다.\")\n",
    "        else:\n",
    "            print(\"기타 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9752b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기타 괴롭힘 대화 입니다.\n"
     ]
    }
   ],
   "source": [
    "category_predict('아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나보네 그럼 취소할까요 아가씨 내 여기단골이니 담에 갖다줄께 저도 알바생이라 외상안됩니다 아따 누가 떼먹는다고 그러나 갖다준다고 안됩니다 자꾸이럼 경찰불러요 아가씨 담배피는교 그건 왜 물으세요 그람 아가씨 담배 한대만 빌립시다 내 지금 지갑도 잃어버리고 기분이 그래서 그러니 여기요  아따 주는김에 한개더 주면 되겠네')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d35df2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갈취 대화 입니다.\n"
     ]
    }
   ],
   "source": [
    "category_predict('이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 요즘 듣는 것도 들어봐 음 난 좀 별론데 좋을 줄 알았는데 아쉽네 내 취향은 아닌 듯 배고프다 밥이나 먹으러 가자 그래')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "055a37d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 요즘 듣는 것도 들어봐 음 난 좀 별론데 좋을 줄 알았는데 아쉽네 내 취향은 아닌 듯 배고프다 밥이나 먹으러 가자 그래'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_test['conversation'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e056b",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393118fd",
   "metadata": {},
   "source": [
    "### training = False 상태의 model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4096f5aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 256, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "==================================================================================================\n",
      "Total params: 177,066,240\n",
      "Trainable params: 0\n",
      "Non-trainable params: 177,066,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216989b",
   "metadata": {},
   "source": [
    "### model의 마지막 레이어에서 customize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "     # trainable 설정\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the target layer and all subsequent layers\n",
    "    for layer in model.layers[-1:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    inputs = model.inputs[:3] # model inputs이라 적힌 layer를 뽑기\n",
    "    dense = model.layers[-1].output # 마지막 layer의 output만 뽑기\n",
    "    \n",
    "    x = GlobalMaxPooling1D(name=\"GMP\")(dense)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu', name=\"1st_dense\")(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(768, activation='relu', name=\"2st_dense\")(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    outputs = keras.layers.Dense(4, activation='softmax', \n",
    "                               kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                              name = 'real_output')(x) # \n",
    "\n",
    "\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226ee126",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 256, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Golbal_Max_Pooling (GlobalMaxPo (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768)          3072        Golbal_Max_Pooling[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1st_dense (Dense)               (None, 256)          196864      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        1st_dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "2st_dense (Dense)               (None, 768)          197376      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 768)          3072        2st_dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "real_output (Dense)             (None, 4)            3076        batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 177,470,724\n",
      "Trainable params: 400,900\n",
      "Non-trainable params: 177,069,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a2bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
